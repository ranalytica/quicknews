
---
output:
  md_document:
    variant: markdown_github
---

#quicknews 

An R package for quickly building multi-lingual web corpora via GoogleNews. The package performs two fairly straightforward functions:  

* It extracts metadata for current articles posted on GoogleNews (via RSS) based on user-specified search parameters.
* It extracts/scrapes article content from url included in metadata.

The latter returns a data frame, which includes the metadata (for all successfully scraped texts), along with the full text for each article (represented as a single row), ie, a [TIF](https://github.com/ropensci/tif#text-interchange-formats)-compliant corpus dataframe. 

The output can subsequently be annotated using `spacyr` or `cleanNLP`.

Package functionality is dependent on the `boilerpipeR`, `xml2`, and `RCurl` packages. 

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(quicknews)#devtools::install_github("jaytimm/quicknews")
```


###qnews_get_meta()

`qnews_get_meta` retrieves metadata based on user-specified search paramaters from the GoogleNews RSS feed.  Below we search for US-based, business-related articles written in Spanish. Each call to the RSS returns 20 items.

```{r}
es_us_business_meta <- quicknews::qnews_get_meta  (language="es", country="us", type="topic", search='business')
```

Additional country/language searches (that I know work) include US-English (en/us), Mexico-Spanish (es/mx), France-French (fr/fr), and Germany-German (de/de). Also, note that "es" here actually means "es-419", or Spanish spoken in Latin America.    

Additional topics used in GoogleNews include Nation, World, Health, Science, Sports, Technology, and some others.  When the `type` parameter is set to "term", the `search` parameter can be set to anything.  When the `type` parameter is set to "topstories", the `search` parameter is ignored.

In theory, larger corpora could be constructed by applying `qnews_get_meta` across multiple topics (and over time).


Metadata include:
```{r echo=FALSE}
colnames(es_us_business_meta)
```

Article publication dates, sources, and titles: 

```{r}
es_us_business_meta%>%
  select(date:title)
```



###qnews_scrape_web()

The second function, `qnews_scrape_web`, scrapes text from the web addresses included in the output from `qnews_get_meta`.  

```{r}
es_us_business_corpus <- es_us_business_meta%>% 
  quicknews::qnews_scrape_web (link_var='link')
```

Example text from our new corpus data frame is presented below. As can be noted, not all of the articles retrieved from the RSS feed (n=20) were successfully scraped.  Not all websites allow non-Google entities to scrape their sites.  

```{r}
paste0(substr(es_us_business_corpus$text,1,55),"...")
```


Again, output from `qnews_scrape_web` can be piped directly into corpus annotation functions made available in `cleanNLP` or `spacyr`.  

